{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1882441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from data_loaders import dataloader_dict,data_dict\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87837d52",
   "metadata": {},
   "source": [
    "# Defining parameters for reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26da4da",
   "metadata": {},
   "source": [
    "- **root_path**： the path to the dataset\n",
    "- **data_name**:  \"ucihar\",  \"pamap2\"\n",
    "- **difference Bool**: wheather to perform the differencing\n",
    "- **datanorm_type** ： The methods used for normalization ： ,\"standardization\", \"minmax\"\n",
    "- **spectrogram** Bool : Whether to convert the data into Spectorgram\n",
    "\n",
    "\n",
    "\n",
    "The following parameters are for dataloader\n",
    "- **batch_size** \n",
    "- **shuffle**\n",
    "- **drop_last**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386f840",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abedc5f",
   "metadata": {},
   "source": [
    "## UCI HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e909c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ramdom split\n",
      "Train data number :  5372.0\n",
      "The number of classes is :  6\n",
      "The input_length  is :  128\n",
      "The channel_in is :  18\n",
      "Test data number :  2947.0\n",
      "Validation data number :  1980.0\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "\n",
    "args.root_path = r\"D:\\TECO\\Paper\\datasets\\UCI HAR Dataset\"  \n",
    "args.data_name = \"ucihar\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6af50",
   "metadata": {},
   "source": [
    "## Pamap2\n",
    "    This dataset is 1.6G, It may takes longer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc6f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  13839\n",
      "The number of classes is :  13\n",
      "The input_length  is :  512\n",
      "The channel_in is :  72\n",
      "Test data number :  2439\n",
      "Validation data number :  2660\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "\n",
    "args.root_path = r\"D:\\TECO\\Paper\\backup\\dataset_activity_recognition\\PAMAP2\\PAMAP2_Dataset\\Protocol\"\n",
    "args.data_name = \"pamap2\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bea413",
   "metadata": {},
   "source": [
    "## Opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78099b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  33587\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  226\n",
      "Test data number :  7317\n",
      "Validation data number :  9909\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()  \n",
    "\n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\Opportunity_Dataset\\dataset\"\n",
    "args.data_name = \"opportunity\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7dd2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
