{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1882441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from data_loaders import dataloader_dict,data_dict\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87837d52",
   "metadata": {},
   "source": [
    "# Defining parameters for reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26da4da",
   "metadata": {},
   "source": [
    "- **root_path**： the path to the dataset\n",
    "- **data_name**:  \"ucihar\",  \"pamap2\"\n",
    "- **difference Bool**: wheather to perform the differencing\n",
    "- **datanorm_type** ： The methods used for normalization ： ,\"standardization\", \"minmax\"\n",
    "- **spectrogram** Bool : Whether to convert the data into Spectorgram\n",
    "\n",
    "\n",
    "\n",
    "The following parameters are for dataloader\n",
    "- **batch_size** \n",
    "- **shuffle**\n",
    "- **drop_last**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386f840",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dacc8",
   "metadata": {},
   "source": [
    "## FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344aa77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  37674\n",
      "The number of classes is :  7\n",
      "The input_length  is :  30\n",
      "The channel_in is :  120\n",
      "Test data number :  125566\n",
      "Validation data number :  12558\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path = r\"D:\\TECO\\Paper\\datasets\\Fusion_Dataset\"\n",
    "args.data_name = \"fusion\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ead06",
   "metadata": {},
   "source": [
    "## WISDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8710c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  67930\n",
      "The number of classes is :  6\n",
      "The input_length  is :  30\n",
      "The channel_in is :  6\n",
      "Test data number :  173107\n",
      "Validation data number :  14476\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path = r\"D:\\TECO\\Paper\\datasets\\WISDM_Dataset\"\n",
    "args.data_name = \"wisdm\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a1b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "068348e4",
   "metadata": {},
   "source": [
    "## MHealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5b67d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  8101\n",
      "The number of classes is :  12\n",
      "The input_length  is :  75\n",
      "The channel_in is :  46\n",
      "Test data number :  66220\n",
      "Validation data number :  2621\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path = r\"D:\\TECO\\Paper\\datasets\\Mhealth_Dataset\"\n",
    "args.data_name = \"mhealth\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22209e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.no_drop_activites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9ff290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7443084",
   "metadata": {},
   "source": [
    "## Skoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819edb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random split\n",
      "Train data number :  7059\n",
      "The number of classes is :  10\n",
      "The input_length  is :  98\n",
      "The channel_in is :  60\n",
      "Test data number :  105677\n",
      "Validation data number :  1765\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path  = r\"D:\\TECO\\Paper\\datasets\\Skoda HAR Dataset\"\n",
    "args.data_name = \"skoda\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a6a135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abedc5f",
   "metadata": {},
   "source": [
    "## UCI HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e909c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ramdom split\n",
      "Train data number :  5635.0\n",
      "The number of classes is :  6\n",
      "The input_length  is :  128\n",
      "The channel_in is :  18\n",
      "Test data number :  2947.0\n",
      "Validation data number :  1717.0\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "\n",
    "args.root_path = r\"D:\\TECO\\Paper\\datasets\\UCI HAR Dataset\"  \n",
    "args.data_name = \"ucihar\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6af50",
   "metadata": {},
   "source": [
    "## Pamap2\n",
    "    This dataset is 1.6G, It may takes longer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc6f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  13839\n",
      "The number of classes is :  12\n",
      "The input_length  is :  512\n",
      "The channel_in is :  72\n",
      "Test data number :  243171\n",
      "Validation data number :  2660\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "\n",
    "args.root_path = r\"D:\\TECO\\Paper\\backup\\dataset_activity_recognition\\PAMAP2\\PAMAP2_Dataset\\Protocol\"\n",
    "args.data_name = \"pamap2\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bea413",
   "metadata": {},
   "source": [
    "## Opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78099b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  33587\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  226\n",
      "Test data number :  107294\n",
      "Validation data number :  9909\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()  \n",
    "\n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\Opportunity_Dataset\\dataset\"\n",
    "args.data_name = \"opportunity\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2731d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.window_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b6eb5",
   "metadata": {},
   "source": [
    "## Daphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578dc1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  33810\n",
      "The number of classes is :  2\n",
      "The input_length  is :  192\n",
      "The channel_in is :  18\n",
      "Test data number :  210617\n",
      "Validation data number :  6372\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()  \n",
    "\n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\Daphnet_Dataset\\dataset\"\n",
    "args.data_name = \"daphnet\"\n",
    "args.difference = True \n",
    "args.datanorm_type = None\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5701d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 192, 18])\n"
     ]
    }
   ],
   "source": [
    "for x,y in vali_data_loader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e1d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 192, 18])\n"
     ]
    }
   ],
   "source": [
    "for x,y in test_data_loader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee59d1",
   "metadata": {},
   "source": [
    "## USC-HAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a18d7721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects Split\n",
      "Train data number :  44029\n",
      "The number of classes is :  12\n",
      "The input_length  is :  100\n",
      "The channel_in is :  12\n",
      "Test data number :  454321\n",
      "Validation data number :  13045\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path  = r\"D:\\TECO\\Paper\\datasets\\USC_HAD_Dataset\"\n",
    "args.data_name = \"uschad\"\n",
    "args.difference = True \n",
    "args.datanorm_type = \"standardization\"\n",
    "args.spectrogram = False\n",
    "\n",
    "args.batch_size = 32\n",
    "args.shuffle  = True\n",
    "args.drop_last = False\n",
    "\n",
    "# load the data\n",
    "\n",
    "data = data_dict[args.data_name](args)\n",
    "\n",
    "# form the train test validation data\n",
    "train_data  = dataloader_dict[args.data_name](args,data,\"train\")\n",
    "test_data  = dataloader_dict[args.data_name](args,data,\"test\")\n",
    "vali_data  = dataloader_dict[args.data_name](args,data,\"vali\")\n",
    "\n",
    "\n",
    "# form the dataloader\n",
    "train_data_loader = DataLoader(train_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "vali_data_loader = DataLoader(vali_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)\n",
    "\n",
    "test_data_loader = DataLoader(test_data,  \n",
    "                                batch_size   =  args.batch_size,\n",
    "                                shuffle      =  args.shuffle,\n",
    "                                num_workers  =  0,\n",
    "                                drop_last    =  args.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c21db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
